#!/usr/bin/env python3
import base64
import csv
import json
import os
import pickle
import shutil
import time
import zlib
from logging import INFO
from typing import List, Tuple, Dict, Optional

import docker
import logging
import matplotlib
from flwr.common import (
    ndarrays_to_parameters,
    parameters_to_ndarrays,
    Parameters,
    FitRes,
    EvaluateRes,
    Scalar,
    FitIns,
    EvaluateIns,
)
from flwr.server import (
    ServerConfig,
    start_server
)
from flwr.server.client_manager import ClientManager
from flwr.server.client_proxy import ClientProxy
from flwr.server.strategy import Strategy

from logger import log
from taskA import Net as NetA, get_weights as get_weights_A, set_weights as set_weights_A

docker_client = docker.from_env()
from APClient import ClientRegistry
import torch
from adaptation import AdaptationManager

current_dir = os.path.dirname(os.path.abspath(__file__))
folders_to_delete = ["performance", "model_weights"]

for folder in folders_to_delete:
    folder_path = os.path.join(current_dir, folder)
    if os.path.exists(folder_path):
        # svuota la cartella senza toccare il mount point
        for nome in os.listdir(folder_path):
            percorso = os.path.join(folder_path, nome)
            if os.path.isdir(percorso):
                shutil.rmtree(percorso, ignore_errors=True)
            else:
                try:
                    os.remove(percorso)
                except OSError:
                    pass

client_registry = ClientRegistry()

################### GLOBAL PARAMETERS
global ADAPTATION

global metrics_history
metrics_history = {}

global CLIENT_SELECTOR, CLIENT_CLUSTER, MESSAGE_COMPRESSOR, MODEL_COVERSIONING, MULTI_TASK_MODEL_TRAINER, HETEROGENEOUS_DATA_HANDLER
CLIENT_SELECTOR = False
CLIENT_CLUSTER = False
MESSAGE_COMPRESSOR = False
MODEL_COVERSIONING = False
MULTI_TASK_MODEL_TRAINER = False
HETEROGENEOUS_DATA_HANDLER = False

# Non inizializziamo global_metrics con una chiave fissa, verrà creata dinamicamente
global_metrics = {}

matplotlib.use('Agg')
current_dir = os.path.abspath(os.path.dirname(__file__))


def config_patterns(config):
    global CLIENT_SELECTOR, CLIENT_CLUSTER, MESSAGE_COMPRESSOR, MODEL_COVERSIONING, MULTI_TASK_MODEL_TRAINER, HETEROGENEOUS_DATA_HANDLER

    for pattern_name, pattern_info in config.items():
        if pattern_name == "client_selector":
            CLIENT_SELECTOR = pattern_info["enabled"]
        elif pattern_name == "client_cluster":
            CLIENT_CLUSTER = pattern_info["enabled"]
        elif pattern_name == "message_compressor":
            MESSAGE_COMPRESSOR = pattern_info["enabled"]
        elif pattern_name == "model_co-versioning_registry":
            MODEL_COVERSIONING = pattern_info["enabled"]
        elif pattern_name == "multi-task_model_trainer":
            MULTI_TASK_MODEL_TRAINER = pattern_info["enabled"]
        elif pattern_name == "heterogeneous_data_handler":
            HETEROGENEOUS_DATA_HANDLER = pattern_info["enabled"]


# Path to the 'configuration' directory
config_dir = os.path.join(current_dir, 'configuration')
config_file = os.path.join(config_dir, 'config.json')

# Lettura dei parametri dal file di configurazione
if os.path.exists(config_file):
    with open(config_file, 'r') as f:
        config = json.load(f)
    ADAPTATION = config.get('adaptation', False)

    num_rounds = int(config.get('rounds', 10))
    client_count = int(config.get('clients', 2))
    config_patterns(config["patterns"])

    CLIENT_DETAILS = config.get("client_details", [])
    client_details_structure = []
    for client in CLIENT_DETAILS:
        client_details_structure.append({
            "client_id": client.get("client_id"),
            "cpu": client.get("cpu"),
            "ram": client.get("ram"),
            "cpu_percent": client.get("cpu_percent"),
            "ram_percent": client.get("ram_percent"),
            "dataset": client.get("dataset"),
            "data_distribution_type": client.get("data_distribution_type"),
            "model": client.get("model")
        })
    GLOBAL_CLIENT_DETAILS = client_details_structure

currentRnd = 0

performance_dir = './performance/'
if not os.path.exists(performance_dir):
    os.makedirs(performance_dir)

csv_file = os.path.join(performance_dir, 'FLwithAP_performance_metrics.csv')
if os.path.exists(csv_file):
    os.remove(csv_file)

with open(csv_file, 'w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow([
        'Client ID', 'FL Round', 'Training Time', 'JSD', 'HDH Time', 'Communication Time', 'Total Time of FL Round',
        '# of CPU', 'CPU Usage (%)', 'RAM Usage (%)',
        'Model Type', 'Data Distr. Type', 'Dataset',
        'Train Loss', 'Train Accuracy', 'Train F1', 'Train MAE',
        'Val Loss', 'Val Accuracy', 'Val F1', 'Val MAE'
    ])


def log_round_time(
        client_id, fl_round,
        training_time, jsd, hdh_ms, communication_time, time_between_rounds,
        n_cpu, cpu_percent, ram_percent,
        client_model_type, data_distr, dataset_value,
        already_logged, srt1, srt2, agg_key
):
    try:
        client_id = docker_client.containers.get(client_id).name
    except Exception:
        client_id = client_id

    if client_id.startswith("docker-"):
        client_id = client_id[len("docker-"):]
        client_id = client_id.replace("-", " ").title()

    if agg_key not in global_metrics:
        global_metrics[agg_key] = {
            "train_loss": [], "train_accuracy": [], "train_f1": [], "train_mae": [],
            "val_loss": [], "val_accuracy": [], "val_f1": [], "val_mae": []
        }

    tm = global_metrics[agg_key]
    train_loss = tm["train_loss"][-1] if tm["train_loss"] else None
    train_accuracy = tm["train_accuracy"][-1] if tm["train_accuracy"] else None
    train_f1 = tm["train_f1"][-1] if tm["train_f1"] else None
    train_mae = tm["train_mae"][-1] if tm["train_mae"] else None
    val_loss = tm["val_loss"][-1] if tm["val_loss"] else None
    val_accuracy = tm["val_accuracy"][-1] if tm["val_accuracy"] else None
    val_f1 = tm["val_f1"][-1] if tm["val_f1"] else None
    val_mae = tm["val_mae"][-1] if tm["val_mae"] else None

    if already_logged:
        srt2 = None

    with open(csv_file, 'a', newline='') as file:
        writer = csv.writer(file)
        writer.writerow([
            client_id,
            fl_round + 1,
            f"{training_time:.2f}",
            f"{jsd:.2f}",
            f"{hdh_ms:.2f}",
            f"{communication_time:.2f}",
            f"{time_between_rounds:.2f}",
            n_cpu,
            f"{cpu_percent:.0f}",
            f"{ram_percent:.0f}",
            client_model_type,
            data_distr,
            dataset_value,
            f"{train_loss:.2f}" if train_loss is not None else "",
            f"{train_accuracy:.4f}" if train_accuracy is not None else "",
            f"{train_f1:.4f}" if train_f1 is not None else "",
            f"{train_mae:.4f}" if train_mae is not None else "",
            f"{val_loss:.2f}" if val_loss is not None else "",
            f"{val_accuracy:.4f}" if val_accuracy is not None else "",
            f"{val_f1:.4f}" if val_f1 is not None else "",
            f"{val_mae:.4f}" if val_mae is not None else "",
        ])


def preprocess_csv():
    import pandas as pd
    import seaborn as sns

    df = pd.read_csv(csv_file)

    df["Client Number"] = (
        df["Client ID"]
        .astype(str)
        .str.extract(r"(\d+)")[0]
        .astype(int)
    )

    df["Training Time"] = pd.to_numeric(df["Training Time"], errors="coerce")
    df["JSD"] = pd.to_numeric(df["JSD"], errors="coerce")

    df["Total Time of FL Round"] = pd.to_numeric(
        df["Total Time of FL Round"], errors="coerce"
    )

    df["Total Time of FL Round"] = (
        df.groupby("FL Round")["Total Time of FL Round"]
        .transform(lambda x: [None] * (len(x) - 1) + [x.iloc[-1]])
    )

    df.sort_values(["FL Round", "Client Number"], inplace=True)
    cols_round = ["Total Time of FL Round"] + list(
        df.columns[df.columns.get_loc("Train Loss"):]
    )

    def fix_round_values(subdf):
        subdf = subdf.copy()
        last = subdf["Client Number"].max()
        for col in cols_round:
            vals = subdf[col].dropna()
            v = vals.iloc[-1] if not vals.empty else pd.NA
            subdf.loc[subdf["Client Number"] == last, col] = v
            subdf.loc[subdf["Client Number"] != last, col] = pd.NA
        return subdf

    df = df.groupby("FL Round", group_keys=False).apply(fix_round_values)
    df.drop(columns=["Client Number"], inplace=True)
    df.to_csv(csv_file, index=False)
    sns.set_theme(style="ticks")


def weighted_average_global(metrics, agg_model_type, srt1, srt2, time_between_rounds):
    if agg_model_type not in global_metrics:
        global_metrics[agg_model_type] = {
            "train_loss": [],
            "train_accuracy": [],
            "train_f1": [],
            "train_mae": [],
            "val_loss": [],
            "val_accuracy": [],
            "val_f1": [],
            "val_mae": [],
            "jsd": []
        }
    examples = [num_examples for num_examples, _ in metrics]
    total_examples = sum(examples)
    if total_examples == 0:
        return {
            "train_loss": float('inf'),
            "train_accuracy": 0.0,
            "train_f1": 0.0,
            "train_mae": 0.0,
            "val_loss": float('inf'),
            "val_accuracy": 0.0,
            "val_f1": 0.0,
            "val_mae": 0.0,
        }

    # se il valore è None, viene usato 0
    train_losses = [n * (m.get("train_loss") or 0) for n, m in metrics]
    train_accuracies = [n * (m.get("train_accuracy") or 0) for n, m in metrics]
    train_f1 = [n * (m.get("train_f1") or 0) for n, m in metrics]
    train_maes = [n * (m.get("train_mae") or 0) for n, m in metrics]
    val_losses = [n * (m.get("val_loss") or 0) for n, m in metrics]
    val_accuracies = [n * (m.get("val_accuracy") or 0) for n, m in metrics]
    val_f1 = [n * (m.get("val_f1") or 0) for n, m in metrics]
    val_maes = [n * (m.get("val_mae") or 0) for n, m in metrics]
    jsds = sorted([(m.get("client_id"), m.get("jsd") or 0) for _, m in metrics],
                  key=lambda x: x[0])

    avg_train_loss = sum(train_losses) / total_examples
    avg_train_accuracy = sum(train_accuracies) / total_examples
    avg_train_f1 = sum(train_f1) / total_examples
    avg_train_mae = sum(train_maes) / total_examples
    avg_val_loss = sum(val_losses) / total_examples
    avg_val_accuracy = sum(val_accuracies) / total_examples
    avg_val_f1 = sum(val_f1) / total_examples
    avg_val_mae = sum(val_maes) / total_examples
    sorted_jsds = tuple([tup[1] for tup in jsds])

    global_metrics[agg_model_type]["train_loss"].append(avg_train_loss)
    global_metrics[agg_model_type]["train_accuracy"].append(avg_train_accuracy)
    global_metrics[agg_model_type]["train_f1"].append(avg_train_f1)
    global_metrics[agg_model_type]["train_mae"].append(avg_train_mae)
    global_metrics[agg_model_type]["val_loss"].append(avg_val_loss)
    global_metrics[agg_model_type]["val_accuracy"].append(avg_val_accuracy)
    global_metrics[agg_model_type]["val_f1"].append(avg_val_f1)
    global_metrics[agg_model_type]["val_mae"].append(avg_val_mae)
    global_metrics[agg_model_type]["jsd"].append(sorted_jsds)

    client_data_list = []
    for num_examples, m in metrics:
        if num_examples == 0:
            continue
        client_id = m.get("client_id")
        model_type = m.get("model_type", "N/A")
        data_distr = m.get("data_distribution_type", "N/A")
        dataset_value = m.get("dataset", "N/A")
        training_time = m.get("training_time") or 0.0
        jsd = m.get("jsd") or 0.0
        communication_time = m.get("communication_time") or 0.0
        n_cpu = m.get("n_cpu") or 0
        hdh_ms = m.get("hdh_ms") or 0.0
        cpu_percent = m.get("cpu_percent") or 0.0
        ram_percent = m.get("ram_percent") or 0.0
        if client_id:
            client_data_list.append((
                client_id,
                training_time,
                jsd,
                hdh_ms,
                communication_time,
                time_between_rounds,
                n_cpu,
                cpu_percent,
                ram_percent,
                model_type,
                data_distr,
                dataset_value,
                srt1,
                srt2
            ))

    num_clients = len(client_data_list)
    for idx, client_data in enumerate(client_data_list):
        (
            client_id,
            training_time,
            jsd,
            hdh_ms,
            communication_time,
            time_between_rounds,
            n_cpu,
            cpu_percent,
            ram_percent,
            model_type,
            data_distr,
            dataset_value,
            srt1,
            srt2
        ) = client_data
        already_logged = (idx != num_clients - 1)
        log_round_time(
            client_id,
            currentRnd - 1,
            training_time,
            jsd,
            hdh_ms,
            communication_time,
            time_between_rounds,
            n_cpu,
            cpu_percent,
            ram_percent,
            model_type,
            data_distr,
            dataset_value,
            already_logged,
            srt1,
            srt2,
            agg_model_type
        )

    return {
        "train_loss": avg_train_loss,
        "train_accuracy": avg_train_accuracy,
        "train_f1": avg_train_f1,
        "train_mae": avg_train_mae,
        "val_loss": avg_val_loss,
        "val_accuracy": avg_val_accuracy,
        "val_f1": avg_val_f1,
        "val_mae": avg_val_mae,
        "jsd": sorted_jsds
    }


parametersA = ndarrays_to_parameters(get_weights_A(NetA()))
client_model_mapping = {}


class MultiModelStrategy(Strategy):
    def __init__(self, initial_parameters_a: Parameters):
        self.round_start_time: float | None = None
        self.parameters_a = initial_parameters_a
        self._send_ts = {}
        banner = r"""
  ___  ______  ___ ______       _ 
 / _ \ | ___ \/   ||  ___|     | |
/ /_\ \| |_/ / /| || |_ ___  __| |
|  _  ||  __/ /_| ||  _/ _ \/ _` |
| | | || |  \___  || ||  __/ (_| |
\_| |_/\_|      |_/\_| \___|\__,_| v.1.5.0

"""
        log(INFO, "==========================================")
        for raw in banner.splitlines()[1:]:
            line = raw.replace(" ", "\u00A0")
            log(INFO, line)
        log(INFO, "==========================================")
        log(INFO, "Simulation Started!")
        log(INFO, "List of the Architectural Patterns enabled:")

        enabled_patterns = []
        for pattern_name, pattern_info in config["patterns"].items():
            if pattern_info["enabled"]:
                enabled_patterns.append((pattern_name, pattern_info))

        if ADAPTATION:
            log(INFO, "Adaptation Enabled ✅")
            self.adapt_mgr = AdaptationManager(True, config)
            self.adapt_mgr.describe()
        else:
            self.adapt_mgr = AdaptationManager(False, config)

        if not enabled_patterns:
            log(INFO, "No patterns are enabled.")
        else:
            for pattern_name, pattern_info in enabled_patterns:
                pattern_str = pattern_name.replace('_', ' ').title()
                log(INFO, f"{pattern_str} ✅")
                if pattern_info["params"]:
                    log(INFO, f" AP Parameters: {pattern_info['params']}")
                time.sleep(1)

        log(INFO, "==========================================")

    def initialize_parameters(self, client_manager: ClientManager) -> Optional[Parameters]:
        return None

    def configure_fit(
            self,
            server_round: int,
            parameters: Parameters,
            client_manager: ClientManager,
    ) -> List[Tuple[ClientProxy, FitIns]]:
        client_manager.wait_for(client_count)
        self.round_start_time = time.time()
        available = client_manager.num_available()
        if available < 1:
            return []

        num_fit = available
        clients: List[ClientProxy] = client_manager.sample(
            num_clients=num_fit,
            min_num_clients=1
        )

        base_params: Parameters = self.parameters_a if self.parameters_a is not None else parameters
        if base_params is None:
            return []

        fake_parameters = Parameters(tensors=[], tensor_type=base_params.tensor_type)
        blob = pickle.dumps(base_params, protocol=pickle.HIGHEST_PROTOCOL)
        compressed = zlib.compress(blob, level=1)
        compressed_parameters_b64 = base64.b64encode(compressed).decode("ascii")
        fit_configurations: List[Tuple[ClientProxy, FitIns]] = []
        for client in clients:
            self._send_ts[client.cid] = time.time()
            if 'MESSAGE_COMPRESSOR' in globals() and MESSAGE_COMPRESSOR:
                cfg = {"compressed_parameters_b64": compressed_parameters_b64}
                fit_ins = FitIns(fake_parameters, cfg)
            else:
                fit_ins = FitIns(base_params, {})

            fit_configurations.append((client, fit_ins))

        return fit_configurations

    def aggregate_fit(
            self,
            server_round: int,
            results: List[Tuple[ClientProxy, FitRes]],
            failures: List[BaseException],
    ) -> Optional[Tuple[Parameters, Dict[str, Scalar]]]:
        global previous_round_end_time, currentRnd

        agg_start = time.time()
        round_total_time = time.time() - self.round_start_time
        log(INFO, f"Results Aggregated in {round_total_time:.2f} seconds.")

        results_a = []
        training_times = []
        currentRnd += 1
        model_type = None  # Initialize to handle case when all clients fail

        for client_proxy, fit_res in results:
            if fit_res.num_examples == 0:
                training_time = None
                communication_time = None
                compressed_parameters_hex = None
                client_id = client_proxy.cid
                model_type = None
                metrics = {
                    "train_loss": None,
                    "train_accuracy": None,
                    "train_f1": None,
                    "train_mae": None,
                    "val_loss": None,
                    "val_accuracy": None,
                    "val_f1": None,
                    "val_mae": None,
                    "training_time": None,
                    "communication_time": None,
                    "compressed_parameters_hex": None,
                    "client_id": client_id,
                    "model_type": None,
                }
            else:
                metrics = fit_res.metrics or {}
                training_time = metrics.get("training_time")
                communication_time = metrics.get("communication_time")
                compressed_parameters_b64 = metrics.get("compressed_parameters_b64")
                client_id = metrics.get("client_id")
                model_type = metrics.get("model_type")
                hdh_ms = metrics.get("hdh_ms", 0.0)
                client_model_mapping[client_id] = model_type
                recv_ts = metrics.get("client_sent_ts", None) or time.time()
                send_ts = self._send_ts.get(client_proxy.cid, recv_ts)
                rt_total = recv_ts - send_ts
                train_t = training_time or 0.0
                server_comm_time = max(rt_total - train_t - hdh_ms, 0.0)
                if metrics.get("communication_time") is None:
                    metrics["communication_time"] = server_comm_time
                else:
                    metrics["server_comm_time"] = server_comm_time

            if MESSAGE_COMPRESSOR and compressed_parameters_b64:
                compressed = base64.b64decode(compressed_parameters_b64)
                decompressed = pickle.loads(zlib.decompress(compressed))
                fit_res.parameters = ndarrays_to_parameters(decompressed)

            if training_time is not None:
                training_times.append(training_time)

            results_a.append((fit_res.parameters, fit_res.num_examples, metrics))

        previous_round_end_time = time.time()
        max_train = max(training_times) if training_times else 0.0
        agg_end = time.time()
        aggregation_time = agg_end - agg_start

        # Check if all clients failed
        if not results_a or all(num_ex == 0 for _, num_ex, _ in results_a):
            raise RuntimeError(
                f"All {len(failures)} clients failed in round {server_round}. "
                "Check client logs for details (likely data loading or model errors)."
            )

        # Use fallback model type if not set
        if model_type is None:
            model_type = GLOBAL_CLIENT_DETAILS[0].get("model", "unknown")

        self.parameters_a = self.aggregate_parameters(
            results_a,
            model_type,
            max_train,
            communication_time,
            round_total_time
        )

        aggregated_model = NetA()
        params_list = parameters_to_ndarrays(self.parameters_a)
        set_weights_A(aggregated_model, params_list)

        if MODEL_COVERSIONING:
            server_folder = os.path.join("model_weights", "server")
            os.makedirs(server_folder, exist_ok=True)
            path = os.path.join(server_folder, f"MW_round{currentRnd}.pt")
            torch.save(aggregated_model.state_dict(), path)
            log(INFO, f"Aggregated model weights saved to {path}")

        # FIXME: only works if all clients have the same model type
        model_under_training = GLOBAL_CLIENT_DETAILS[0]["model"]
        if model_under_training not in metrics_history:
            metrics_history[model_under_training] = {key: [global_metrics[model_type][key][-1]]
                                                     for key in global_metrics[model_type]}
        else:
            for key in global_metrics[model_type]:
                metrics_history[model_under_training][key].append(global_metrics[model_type][key][-1])

        metrics_aggregated: Dict[str, Scalar] = {}
        if any(global_metrics.get(model_type, {}).values()):
            metrics_aggregated[model_type] = {
                key: global_metrics[model_type][key][-1]
                if global_metrics[model_type][key] else None
                for key in global_metrics[model_type]
            }

        preprocess_csv()
        round_csv = os.path.join(
            performance_dir,
            f"FLwithAP_performance_metrics_round{currentRnd}.csv"
        )
        shutil.copy(csv_file, round_csv)

        log(INFO, metrics_history)
        next_round_config = self.adapt_mgr.config_next_round(metrics_history, round_total_time)
        config_patterns(next_round_config)

        return self.parameters_a, metrics_aggregated

    def aggregate_parameters(self, results, agg_model_type, srt1, srt2, time_between_rounds):
        total_examples = sum([num_examples for _, num_examples, _ in results])
        new_weights = None

        metrics = []
        for client_params, num_examples, client_metrics in results:
            client_weights = parameters_to_ndarrays(client_params)
            weight = num_examples / total_examples
            if new_weights is None:
                new_weights = [w * weight for w in client_weights]
            else:
                new_weights = [nw + w * weight for nw, w in zip(new_weights, client_weights)]
            metrics.append((num_examples, client_metrics))

        weighted_average_global(metrics, agg_model_type, srt1, srt2, time_between_rounds)
        return ndarrays_to_parameters(new_weights)

    def configure_evaluate(
            self,
            server_round: int,
            parameters: Parameters,
            client_manager: ClientManager,
    ) -> List[Tuple[ClientProxy, EvaluateIns]]:
        # log(INFO, f"Evaluating Performance Metrics...")
        return []

    def aggregate_evaluate(
            self,
            server_round: int,
            results: List[Tuple[ClientProxy, EvaluateRes]],
            failures: List[BaseException],
    ) -> Optional[float]:
        return None

    def evaluate(
            self,
            server_round: int,
            parameters: Parameters,
    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:
        return None


if __name__ == "__main__":
    strategy = MultiModelStrategy(
        initial_parameters_a=parametersA,
    )

    start_server(
        server_address="[::]:8080",
        config=ServerConfig(num_rounds=num_rounds),
        strategy=strategy,
    )
